{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HJD-FRbJ0pqQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesunpark1/CTR_Predict_Model/blob/main/Pozalabs_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Environment (필요 모듈 설치 및 라이브러리 불러오기)\n",
        "import glob\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth2 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip3 install -q pyfluidsynth\n",
        "!pip3 install -U magenta apache_beam\n",
        "\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def play(note_sequence):\n",
        "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
        "\n",
        "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
        "                assert_same_length=True, temperature=0.5,\n",
        "                individual_duration=4.0):\n",
        "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
        "  note_sequences = model.interpolate(\n",
        "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
        "      temperature=temperature,\n",
        "      assert_same_length=assert_same_length)\n",
        "\n",
        "  print('Start Seq Reconstruction')\n",
        "  play(note_sequences[0])\n",
        "  print('End Seq Reconstruction')\n",
        "  play(note_sequences[-1])\n",
        "  print('Mean Sequence')\n",
        "  play(note_sequences[num_steps // 2])\n",
        "  print('Start -> End Interpolation')\n",
        "  interp_seq = mm.sequences_lib.concatenate_sequences(\n",
        "      note_sequences, [individual_duration] * len(note_sequences))\n",
        "  play(interp_seq)\n",
        "  mm.plot_sequence(interp_seq)\n",
        "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "\n",
        "print('Done')"
      ],
      "metadata": {
        "id": "cj7a19_8Xgcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnVMxqkYjPEy",
        "outputId": "e7becd27-968d-4f63-a900-7688498af75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Preproc] Generate train tf data"
      ],
      "metadata": {
        "id": "HJD-FRbJ0pqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 셋을 구글 드라이브에 저장 후 압축파일을 풀어줌\n",
        "\n",
        "%cd /content/drive/MyDrive/DATA/pozlabs\n",
        "! wget https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
        "! unzip -qq \"/content/drive/MyDrive/DATA/pozlabs/groove-v1.0.0-midionly.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHCCsNZ41sHM",
        "outputId": "f68eddf4-4f93-4040-e4c6-5dc321dbc025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATA/pozlabs\n",
            "--2023-01-24 03:56:19--  https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 142.250.145.128, 2a00:1450:4013:c14::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3260318 (3.1M) [application/zip]\n",
            "Saving to: ‘groove-v1.0.0-midionly.zip.1’\n",
            "\n",
            "groove-v1.0.0-midio 100%[===================>]   3.11M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-01-24 03:56:19 (37.7 MB/s) - ‘groove-v1.0.0-midionly.zip.1’ saved [3260318/3260318]\n",
            "\n",
            "replace groove/drummer8/session2/25_latin_84_beat_4-4.mid? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "error:  cannot create groove/drummer8/session2/25_latin_84_beat_4-4.mid\n",
            "        No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장 경로 지정\n",
        "\n",
        "INPUT_DIRECTORY=\"/content/drive/MyDrive/DATA/pozlabs/groove\"\n",
        "SEQUENCES_TFRECORD=\"/content/drive/MyDrive/DATA/pozlabs/notesequences.tfrecord\""
      ],
      "metadata": {
        "id": "1Fw545YiwJVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TFrecord 형식으로 저장하는 전처리 진행 \n",
        "\n",
        "%%bash -s \"{INPUT_DIRECTORY}\" \"{SEQUENCES_TFRECORD}\"\n",
        "\n",
        "INPUT_DIRECTORY=\"${1}\"\n",
        "echo ${INPUT_DIRECTORY}\n",
        "\n",
        "SEQUENCES_TFRECORD=\"${2}\"\n",
        "echo ${SEQUENCES_TFRECORD}\n",
        "\n",
        "convert_dir_to_note_sequences \\\n",
        "  --input_dir=${INPUT_DIRECTORY} \\\n",
        "  --output_file=${SEQUENCES_TFRECORD} \\\n",
        "  --recursive"
      ],
      "metadata": {
        "id": "FvCeQOL7wKKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Train] Groovae_4bar MusicVAE Model"
      ],
      "metadata": {
        "id": "52ZhWMhn0wKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Music_VAE 모듈 불러오기 및 모델링을 위한 flags 설정\n",
        "\n",
        "import os\n",
        "\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae import data\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "flags = tf.app.flags"
      ],
      "metadata": {
        "id": "2oU2Mt2WfeRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flags.DEFINE_string(\n",
        "    'master', '',\n",
        "    'The TensorFlow master to use.')\n",
        "flags.DEFINE_string(\n",
        "    'examples_path', None,\n",
        "    'Path to a TFRecord file of NoteSequence examples. Overrides the config.')\n",
        "flags.DEFINE_string(\n",
        "    'tfds_name', None,\n",
        "    'TensorFlow Datasets dataset name to use. Overrides the config.')\n",
        "flags.DEFINE_string(\n",
        "    'run_dir', '/content/drive/MyDrive/DATA/pozlabs/',\n",
        "    'Path where checkpoints and summary events will be located during '\n",
        "    'training and evaluation. Separate subdirectories `train` and `eval` '\n",
        "    'will be created within this directory.')\n",
        "flags.DEFINE_integer(\n",
        "    'num_steps', 50000,\n",
        "    'Number of training steps or `None` for infinite.')\n",
        "flags.DEFINE_integer(\n",
        "    'eval_num_batches', None,\n",
        "    'Number of batches to use during evaluation or `None` for all batches '\n",
        "    'in the data source.')\n",
        "flags.DEFINE_integer(\n",
        "    'checkpoints_to_keep', 100,\n",
        "    'Maximum number of checkpoints to keep in `train` mode or 0 for infinite.')\n",
        "flags.DEFINE_integer(\n",
        "    'keep_checkpoint_every_n_hours', 1,\n",
        "    'In addition to checkpoints_to_keep, keep a checkpoint every N hours.')\n",
        "flags.DEFINE_string(\n",
        "    'mode', 'train',\n",
        "    'Which mode to use (`train` or `eval`).')\n",
        "flags.DEFINE_string(\n",
        "    'config', '',\n",
        "    'The name of the config to use.')\n",
        "flags.DEFINE_string(\n",
        "    'hparams', '',\n",
        "    'A comma-separated list of `name=value` hyperparameter values to merge '\n",
        "    'with those in the config.')\n",
        "flags.DEFINE_bool(\n",
        "    'cache_dataset', True,\n",
        "    'Whether to cache the dataset in memory for improved training speed. May '\n",
        "    'cause memory errors for very large datasets.')\n",
        "flags.DEFINE_integer(\n",
        "    'task', 0,\n",
        "    'The task number for this worker.')\n",
        "flags.DEFINE_integer(\n",
        "    'num_ps_tasks', 0,\n",
        "    'The number of parameter server tasks.')\n",
        "flags.DEFINE_integer(\n",
        "    'num_sync_workers', 0,\n",
        "    'The number of synchronized workers.')\n",
        "flags.DEFINE_string(\n",
        "    'eval_dir_suffix', '',\n",
        "    'Suffix to add to eval output directory.')\n",
        "flags.DEFINE_string(\n",
        "    'log', 'DEBUG',\n",
        "    'The threshold for what messages will be logged: '\n",
        "    'DEBUG, INFO, WARN, ERROR, or FATAL.')\n",
        "flags.DEFINE_string(\"f\", \"\", \"kernel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcAoYvXKhk_z",
        "outputId": "a75e31a2-1edb-4963-ed24-430a4fd640d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<absl.flags._flagvalues.FlagHolder at 0x7fb5140c9b50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "flags.FLAGS.run_dir = '/content/drive/MyDrive/DATA/pozlabs/'\n",
        "flags.FLAGS.config = 'groovae_4bar'\n",
        "flags.FLAGS.examples_path = '/content/drive/MyDrive/DATA/pozlabs/notesequences.tfrecord'\n",
        "# flags.FLAGS.tfds_name = 'groove/full-midionly'\n",
        "flags.FLAGS.log = \"INFO\"\n",
        "# flags.FLAGS.hparams = "
      ],
      "metadata": {
        "id": "1We4BuIIgfvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "\n",
        "tf.logging.set_verbosity(FLAGS.log)\n",
        "\n",
        "print(flags.FLAGS.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHh0TvTzhTMM",
        "outputId": "d0f47661-ee05-4126-e938-310f5305dce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "groovae_4bar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs_GlHSwpfII"
      },
      "outputs": [],
      "source": [
        "# 써머리 텐서보드 함수\n",
        "def _trial_summary(hparams, examples_path, output_dir):\n",
        "    \"\"\"Writes a tensorboard text summary of the trial.\"\"\"\n",
        "\n",
        "    examples_path_summary = tf.summary.text(\n",
        "        'examples_path', tf.constant(examples_path, name='examples_path'),\n",
        "        collections=[])\n",
        "\n",
        "    hparams_dict = hparams.values()\n",
        "\n",
        "    # 하이퍼 파라미터\n",
        "    # Create a markdown table from hparams.\n",
        "    header = '| Key | Value |\\n| :--- | :--- |\\n'\n",
        "    keys = sorted(hparams_dict.keys())\n",
        "    lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n",
        "    hparams_table = header + '\\n'.join(lines) + '\\n'\n",
        "\n",
        "    hparam_summary = tf.summary.text(\n",
        "        'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n",
        "        writer.add_summary(examples_path_summary.eval())\n",
        "        writer.add_summary(hparam_summary.eval())\n",
        "        writer.close()\n",
        "\n",
        "# 텐서를 입력값으로 넣는 함수\n",
        "def _get_input_tensors(dataset, config):\n",
        "    \"\"\"Get input tensors from dataset.\"\"\"\n",
        "    batch_size = config.hparams.batch_size\n",
        "    iterator = tf.data.make_one_shot_iterator(dataset)\n",
        "    (input_sequence, output_sequence, control_sequence,\n",
        "    sequence_length) = iterator.get_next()\n",
        "\n",
        "    input_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.input_depth])\n",
        "    output_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.output_depth])\n",
        "    \n",
        "    if not config.data_converter.control_depth:\n",
        "        control_sequence = None\n",
        "    else:\n",
        "        control_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.control_depth])\n",
        "\n",
        "    sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n",
        "\n",
        "    return {\n",
        "        'input_sequence': input_sequence,\n",
        "        'output_sequence': output_sequence,\n",
        "        'control_sequence': control_sequence,\n",
        "        'sequence_length': sequence_length\n",
        "    }\n",
        "\n",
        "#훈련 함수 \n",
        "def train(train_dir,\n",
        "          config,\n",
        "          dataset_fn,\n",
        "          checkpoints_to_keep=5,\n",
        "          keep_checkpoint_every_n_hours=1,\n",
        "          num_steps=None,\n",
        "          master='',\n",
        "          num_sync_workers=0,\n",
        "          num_ps_tasks=0,\n",
        "          task=0):\n",
        "    \"\"\"Train loop.\"\"\"\n",
        "    tf.gfile.MakeDirs(train_dir)\n",
        "    is_chief = (task == 0)\n",
        "\n",
        "    if is_chief:\n",
        "        _trial_summary(\n",
        "            config.hparams, config.train_examples_path or config.tfds_name, train_dir)\n",
        "        \n",
        "    with tf.Graph().as_default():\n",
        "        with tf.device(tf.train.replica_device_setter(\n",
        "            num_ps_tasks, merge_devices=True)):\n",
        "\n",
        "            model = config.model\n",
        "            model.build(config.hparams,\n",
        "                        config.data_converter.output_depth,\n",
        "                        is_training=True)\n",
        "\n",
        "            optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n",
        "\n",
        "            hooks = []\n",
        "            if num_sync_workers:\n",
        "                optimizer = tf.train.SyncReplicasOptimizer(\n",
        "                    optimizer,\n",
        "                    num_sync_workers)\n",
        "                \n",
        "                hooks.append(optimizer.make_session_run_hook(is_chief))\n",
        "\n",
        "            grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n",
        "            global_norm = tf.global_norm(grads)\n",
        "            tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "            if config.hparams.clip_mode == 'value':\n",
        "                g = config.hparams.grad_clip\n",
        "                clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n",
        "            elif config.hparams.clip_mode == 'global_norm':\n",
        "                clipped_grads = tf.cond(\n",
        "                    global_norm < config.hparams.grad_norm_clip_to_zero,\n",
        "                    lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n",
        "                        grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n",
        "                    lambda: [tf.zeros(tf.shape(g)) for g in grads])\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n",
        "\n",
        "            train_op = optimizer.apply_gradients(\n",
        "                list(zip(clipped_grads, var_list)),\n",
        "                global_step=model.global_step,\n",
        "                name='train_step')\n",
        "\n",
        "            logging_dict = {'global_step': model.global_step,\n",
        "                      'loss': model.loss}\n",
        "\n",
        "            hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n",
        "            if num_steps:\n",
        "                hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n",
        "\n",
        "            scaffold = tf.train.Scaffold(\n",
        "                    saver=tf.train.Saver(\n",
        "                        max_to_keep=checkpoints_to_keep,\n",
        "                        keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours\n",
        "                    ))\n",
        "            tf_slim.training.train(\n",
        "                train_op=train_op,\n",
        "                logdir=train_dir,\n",
        "                scaffold=scaffold,\n",
        "                hooks=hooks,\n",
        "                save_checkpoint_secs=60,\n",
        "                master=master,\n",
        "                is_chief=is_chief)\n",
        "# 검증 함수\n",
        "def evaluate(train_dir,\n",
        "             eval_dir,\n",
        "             config,\n",
        "             dataset_fn,\n",
        "             num_batches,\n",
        "             master=''):\n",
        "    \"\"\"Evaluate the model repeatedly.\"\"\"\n",
        "    tf.gfile.MakeDirs(eval_dir)\n",
        "\n",
        "    _trial_summary(\n",
        "        config.hparams, config.eval_examples_path or config.tfds_name, eval_dir)\n",
        "    \n",
        "    with tf.Graph().as_default():\n",
        "        model = config.model\n",
        "        model.build(config.hparams,\n",
        "                    config.data_converter.output_depth,\n",
        "                    is_training=False)\n",
        "\n",
        "        eval_op = model.eval(\n",
        "            **_get_input_tensors(dataset_fn().take(num_batches), config))\n",
        "\n",
        "        hooks = [\n",
        "            tf_slim.evaluation.StopAfterNEvalsHook(num_batches),\n",
        "            tf_slim.evaluation.SummaryAtEndHook(eval_dir)\n",
        "        ]\n",
        "\n",
        "        tf_slim.evaluation.evaluate_repeatedly(\n",
        "            train_dir,\n",
        "            eval_ops=eval_op,\n",
        "            hooks=hooks,\n",
        "            eval_interval_secs=60,\n",
        "            master=master)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not FLAGS.run_dir:\n",
        "    raise ValueError('Invalid run directory: %s' % FLAGS.run_dir)\n",
        "run_dir = os.path.expanduser(FLAGS.run_dir)\n",
        "train_dir = os.path.join(run_dir, 'train')\n",
        "\n",
        "if FLAGS.mode not in ['train', 'eval']:\n",
        "    raise ValueError('Invalid mode: %s' % FLAGS.mode)\n",
        "\n",
        "if FLAGS.config not in configs.CONFIG_MAP:\n",
        "    raise ValueError('Invalid config: %s' % FLAGS.config)\n",
        "\n",
        "config = configs.CONFIG_MAP[FLAGS.config]\n",
        "\n",
        "if FLAGS.hparams:\n",
        "    config.hparams.parse(FLAGS.hparams)\n",
        "config_update_map = {}\n",
        "\n",
        "if FLAGS.examples_path:\n",
        "    config_update_map['%s_examples_path' % FLAGS.mode] = os.path.expanduser(FLAGS.examples_path)\n",
        "\n",
        "if FLAGS.tfds_name:\n",
        "    if FLAGS.examples_path:\n",
        "        raise ValueError('At most one of --examples_path and --tfds_name can be set.')\n",
        "\n",
        "    config_update_map['tfds_name'] = FLAGS.tfds_name\n",
        "    config_update_map['eval_examples_path'] = None\n",
        "    config_update_map['train_examples_path'] = None\n",
        "\n",
        "config = configs.update_config(config, config_update_map)\n",
        "\n",
        "if FLAGS.num_sync_workers:\n",
        "    config.hparams.batch_size //= FLAGS.num_sync_workers\n",
        "\n",
        "def dataset_train_fn():\n",
        "    return data.get_dataset(\n",
        "        config,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        is_training=True,\n",
        "        cache_dataset=FLAGS.cache_dataset)\n",
        "\n",
        "def dataset_eval_fn():\n",
        "    return data.get_dataset(\n",
        "        config,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        is_training=False,\n",
        "        cache_dataset=FLAGS.cache_dataset)"
      ],
      "metadata": {
        "id": "4oAEzKM0hJNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련(학습) 진행\n",
        "\n",
        "train(\n",
        "    train_dir,\n",
        "    config=config,\n",
        "    dataset_fn=dataset_train_fn,\n",
        "    checkpoints_to_keep=FLAGS.checkpoints_to_keep,\n",
        "    keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,\n",
        "    num_steps=FLAGS.num_steps,\n",
        "    master=FLAGS.master,\n",
        "    num_sync_workers=FLAGS.num_sync_workers,\n",
        "    num_ps_tasks=FLAGS.num_ps_tasks,\n",
        "    task=FLAGS.task\n",
        ")"
      ],
      "metadata": {
        "id": "nKxkMqiRi__l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 진행\n",
        "\n",
        "num_batches = FLAGS.eval_num_batches or data.count_examples(\n",
        "    config.eval_examples_path,\n",
        "    config.tfds_name,\n",
        "    config.data_converter,\n",
        "    file_reader) // config.hparams.batch_size\n",
        "\n",
        "eval_dir = os.path.join(run_dir, 'eval' + FLAGS.eval_dir_suffix)\n",
        "\n",
        "evaluate(\n",
        "    train_dir,\n",
        "    eval_dir,\n",
        "    config=config,\n",
        "    dataset_fn=dataset_eval_fn,\n",
        "    num_batches=num_batches,\n",
        "    master=FLAGS.master)"
      ],
      "metadata": {
        "id": "ri9SxZCuph3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "a89b4472-314c-4516-a19a-80626db77baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-19c242626809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfds_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_converter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     file_reader) // config.hparams.batch_size\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0meval_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'file_reader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델링\n",
        "\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "\n",
        "model = TrainedModel(\n",
        "    configs.CONFIG_MAP['groovae_4bar'],  # 4마디 샘플 지정\n",
        "    batch_size=1, \n",
        "    checkpoint_dir_or_path='/content/drive/MyDrive/DATA/pozlabs/train' #학습시킨 체크포인트 경로\n",
        ")"
      ],
      "metadata": {
        "id": "PXXyQb8Yq9q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2b7a95-cc54-4c8f-9216-850334de361d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, GrooveLstmDecoder, and hparams:\n",
            "{'max_seq_len': 64, 'z_size': 256, 'free_bits': 48, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 0.3, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [512]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [256, 256]\n",
            "\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/models/music_vae/lstm_utils.py:94: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  tf.layers.dense(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/contrib/rnn.py:749: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  self._kernel = self.add_variable(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  self._bias = self.add_variable(\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/magenta/contrib/rnn.py:463: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/rnn.py:437: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/models/music_vae/base_model.py:195: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  mu = tf.layers.dense(\n",
            "/usr/local/lib/python3.8/dist-packages/magenta/models/music_vae/base_model.py:200: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  sigma = tf.layers.dense(\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/DATA/pozlabs/train/model.ckpt-36413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 생성\n",
        "import note_seq\n",
        "\n",
        "generated_sequence = model.sample(n=1, length=16*4, temperature=0.5)\n",
        "note_seq.sequence_proto_to_midi_file(generated_sequence[0], '/content/drive/MyDrive/DATA/pozlabs/generated_drum_4bar_2.mid')"
      ],
      "metadata": {
        "id": "Blh5CFBbVCzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crVx0Gfa7rwq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}